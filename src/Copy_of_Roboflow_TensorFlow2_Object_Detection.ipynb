{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF8ysCfYKgTP"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "In this notebook, we implement [The TensorFlow 2 Object Detection Library](https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html) for training on your own dataset.\n",
    "\n",
    "We also recommend reading our blog post on [Train TensorFlow 2 Object Detection on custom data](https://blog.roboflow.com/train-a-tensorflow2-object-detection-model/) side by side.\n",
    "\n",
    "We will take the following steps to implement YOLOv4 on our custom data:\n",
    "* Install TensorFlow2 Object Detection Dependencies\n",
    "* Download Custom TensorFlow2 Object Detection Dataset\n",
    "* Write Custom TensorFlow2 Object Detection Training Configuation\n",
    "* Train Custom TensorFlow2 Object Detection Model\n",
    "* Export Custom TensorFlow2 Object Detection Weights\n",
    "* Use Trained TensorFlow2 Object Detection For Inference on Test Images\n",
    "\n",
    "When you are done you will have a custom detector that you can use. It will make inference like this:\n",
    "\n",
    "#### ![Roboflow Workmark](https://i.imgur.com/L0n564N.png)\n",
    "\n",
    "### **Reach out for support**\n",
    "\n",
    "If you run into any hurdles on your own data set or just want to share some cool results in your own domain, [reach out!](https://roboflow.ai) \n",
    "\n",
    "\n",
    "\n",
    "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7EOtpvlLeS0"
   },
   "source": [
    "# Install TensorFlow2 Object Detection Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZrPFIlNGjP7",
    "outputId": "69ef3135-1fde-48e5-af57-9c86b2c07d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zyuEI6UFSofp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2TJkb89DGL5A"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30czYgV6SNvJ",
    "outputId": "f465debc-86e2-4a13-a420-70a5998ab89a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/pAItologos/RoboFlow\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "path_ROBOFLOW = '/content/drive/MyDrive/pAItologos/RoboFlow'\n",
    "os.makedirs(path_ROBOFLOW, exist_ok=True)\n",
    "%cd /content/drive/MyDrive/pAItologos/RoboFlow\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypWGYdPlLRUN",
    "outputId": "cd089bd0-4721-4e7e-9675-912b84014b95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QPmVBSlLTzM",
    "outputId": "a992fe6f-10f8-4552-be0c-533349d84565"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos.\n",
      "El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos.\n",
      "ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\pasto\\.conda\\envs\\tensorflow\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wHfsJ5nWLWh9"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import colab_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh_HPMOqWH9z",
    "outputId": "b0c1c42f-f4a4-447b-ffe0-094371ef89bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 19:33:48.280316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Running tests under Python 3.7.10: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-06-08 19:33:50.576625: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-08 19:33:50.668261: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-06-08 19:33:50.668353: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6912c59256ec): /proc/driver/nvidia/version does not exist\n",
      "W0608 19:33:51.086745 139895683327872 model_builder.py:1085] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.97s\n",
      "I0608 19:33:51.492994 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.97s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.73s\n",
      "I0608 19:33:52.222704 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.73s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "I0608 19:33:52.569284 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
      "I0608 19:33:52.892838 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0608 19:33:52.895749 139895683327872 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.13s\n",
      "I0608 19:33:56.026315 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0608 19:33:56.027731 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
      "I0608 19:33:56.057797 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I0608 19:33:56.079008 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I0608 19:33:56.102213 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
      "I0608 19:33:56.254391 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
      "I0608 19:33:56.392246 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
      "I0608 19:33:56.536342 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
      "I0608 19:33:56.672640 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
      "I0608 19:33:56.802304 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I0608 19:33:56.835485 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0608 19:33:57.064554 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0608 19:33:57.064839 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0608 19:33:57.064976 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
      "I0608 19:33:57.068041 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:33:57.088522 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:33:57.088732 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:33:57.165235 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:33:57.165539 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:33:57.366645 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:33:57.366897 139895683327872 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0608 19:33:57.587325 139895683327872 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0608 19:33:57.587562 139895683327872 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0608 19:33:58.105852 139895683327872 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0608 19:33:58.106126 139895683327872 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0608 19:33:58.460822 139895683327872 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0608 19:33:58.461073 139895683327872 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0608 19:33:58.944198 139895683327872 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0608 19:33:58.944455 139895683327872 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0608 19:33:59.056671 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0608 19:33:59.129893 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:33:59.201252 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0608 19:33:59.201478 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0608 19:33:59.201557 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
      "I0608 19:33:59.203597 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:33:59.223783 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:33:59.224048 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:33:59.374531 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:33:59.374757 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:33:59.658034 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:33:59.658274 139895683327872 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0608 19:33:59.965403 139895683327872 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0608 19:33:59.965673 139895683327872 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0608 19:34:00.430590 139895683327872 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0608 19:34:00.430915 139895683327872 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0608 19:34:00.912343 139895683327872 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0608 19:34:00.912606 139895683327872 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0608 19:34:01.479353 139895683327872 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0608 19:34:01.479619 139895683327872 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0608 19:34:01.745294 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0608 19:34:01.811125 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:01.885515 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0608 19:34:01.885735 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0608 19:34:01.885831 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0608 19:34:01.887819 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:34:01.905857 139895683327872 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:34:01.906065 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:34:02.060434 139895683327872 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:34:02.060647 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:34:02.500485 139895683327872 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:34:02.500698 139895683327872 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:34:02.784974 139895683327872 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:34:02.785230 139895683327872 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0608 19:34:03.212612 139895683327872 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0608 19:34:03.212875 139895683327872 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0608 19:34:03.633011 139895683327872 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0608 19:34:03.633224 139895683327872 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0608 19:34:04.222596 139895683327872 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0608 19:34:04.222846 139895683327872 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0608 19:34:04.514884 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0608 19:34:04.590746 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:04.671260 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0608 19:34:04.671557 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0608 19:34:04.671659 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
      "I0608 19:34:04.674247 139895683327872 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0608 19:34:04.698076 139895683327872 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0608 19:34:04.698305 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:04.862967 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:04.863224 139895683327872 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0608 19:34:05.166469 139895683327872 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0608 19:34:05.166687 139895683327872 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:34:05.449051 139895683327872 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:34:05.449268 139895683327872 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0608 19:34:05.923240 139895683327872 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0608 19:34:05.923504 139895683327872 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0608 19:34:06.455662 139895683327872 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0608 19:34:06.455868 139895683327872 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0608 19:34:07.158076 139895683327872 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0608 19:34:07.158362 139895683327872 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0608 19:34:07.722334 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0608 19:34:07.803348 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:07.886514 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0608 19:34:07.886732 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0608 19:34:07.886815 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0608 19:34:07.888935 139895683327872 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0608 19:34:07.911252 139895683327872 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0608 19:34:07.911515 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:08.088167 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:08.088454 139895683327872 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0608 19:34:08.555193 139895683327872 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0608 19:34:08.555405 139895683327872 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0608 19:34:08.950071 139895683327872 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0608 19:34:08.950327 139895683327872 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0608 19:34:09.566821 139895683327872 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0608 19:34:09.567027 139895683327872 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0608 19:34:10.206532 139895683327872 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0608 19:34:10.206789 139895683327872 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0608 19:34:11.304792 139895683327872 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0608 19:34:11.305078 139895683327872 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0608 19:34:11.637482 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0608 19:34:11.724592 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:11.829566 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0608 19:34:11.829780 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0608 19:34:11.829863 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0608 19:34:11.832149 139895683327872 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0608 19:34:11.861641 139895683327872 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0608 19:34:11.861929 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:12.138547 139895683327872 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0608 19:34:12.138791 139895683327872 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0608 19:34:12.700174 139895683327872 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0608 19:34:12.700391 139895683327872 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0608 19:34:13.508377 139895683327872 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0608 19:34:13.508624 139895683327872 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0608 19:34:14.250175 139895683327872 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0608 19:34:14.250426 139895683327872 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0608 19:34:15.107975 139895683327872 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0608 19:34:15.108295 139895683327872 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0608 19:34:16.322535 139895683327872 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0608 19:34:16.322779 139895683327872 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0608 19:34:16.852615 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0608 19:34:16.940010 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:17.059374 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0608 19:34:17.059703 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0608 19:34:17.059845 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0608 19:34:17.063727 139895683327872 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0608 19:34:17.085742 139895683327872 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0608 19:34:17.085952 139895683327872 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0608 19:34:17.320917 139895683327872 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0608 19:34:17.321150 139895683327872 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0608 19:34:18.036112 139895683327872 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0608 19:34:18.036491 139895683327872 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0608 19:34:18.855080 139895683327872 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0608 19:34:18.855386 139895683327872 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0608 19:34:19.840179 139895683327872 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0608 19:34:19.840435 139895683327872 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0608 19:34:20.976642 139895683327872 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0608 19:34:20.976852 139895683327872 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0608 19:34:22.643235 139895683327872 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0608 19:34:22.643519 139895683327872 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0608 19:34:23.275688 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0608 19:34:23.371100 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0608 19:34:23.490742 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0608 19:34:23.490975 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0608 19:34:23.491064 139895683327872 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0608 19:34:23.493083 139895683327872 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0608 19:34:23.516617 139895683327872 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0608 19:34:23.516830 139895683327872 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0608 19:34:23.834196 139895683327872 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0608 19:34:23.834403 139895683327872 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0608 19:34:24.464250 139895683327872 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0608 19:34:24.464495 139895683327872 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0608 19:34:25.177521 139895683327872 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0608 19:34:25.177808 139895683327872 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0608 19:34:26.478078 139895683327872 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0608 19:34:26.478333 139895683327872 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0608 19:34:28.173284 139895683327872 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0608 19:34:28.173518 139895683327872 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0608 19:34:30.433371 139895683327872 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0608 19:34:30.433647 139895683327872 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0608 19:34:31.441248 139895683327872 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0608 19:34:31.560004 139895683327872 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 34.89s\n",
      "I0608 19:34:31.730756 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 34.89s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0608 19:34:31.740936 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0608 19:34:31.745790 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0608 19:34:31.746998 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0608 19:34:31.751242 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.01s\n",
      "I0608 19:34:31.760102 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0608 19:34:31.761156 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0608 19:34:31.762786 139895683327872 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 41.246s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "#run model builder test\n",
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VA7Zbo3RLt3W"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: a file path.\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None):\n",
    "  \"\"\"Wrapper function to visualize detections.\n",
    "\n",
    "  Args:\n",
    "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    figsize: size for the figure.\n",
    "    image_name: a name for the image file.\n",
    "  \"\"\"\n",
    "  image_np_with_annotations = image_np.copy()\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_annotations,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.8)\n",
    "  if image_name:\n",
    "    plt.imsave(image_name, image_np_with_annotations)\n",
    "  else:\n",
    "    plt.imshow(image_np_with_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPbU4I7aL9Fl"
   },
   "source": [
    "# Prepare Tensorflow 2 Object Detection Training Data\n",
    "\n",
    "\n",
    "Roboflow automatically creates our TFRecord and label_map files that we need!\n",
    "\n",
    "**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n",
    "\n",
    "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n",
    "\n",
    "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIREg_YwDa7-"
   },
   "source": [
    "![](https://i.imgur.com/ZwMdcbY.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcHJuaurS_AO",
    "outputId": "261fcf05-bbb9-4c68-aed5-cfbf4fc05362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   891  100   891    0     0   1390      0 --:--:-- --:--:-- --:--:--  1392\n",
      "100 22.6M  100 22.6M    0     0  20.5M      0  0:00:01  0:00:01 --:--:--  171M\n",
      "Archive:  roboflow.zip\n",
      " extracting: README.roboflow.txt     \n",
      "   creating: test/\n",
      " extracting: test/mitotic-cells.tfrecord  \n",
      " extracting: test/mitotic-cells_label_map.pbtxt  \n",
      "   creating: train/\n",
      " extracting: train/mitotic-cells.tfrecord  \n",
      " extracting: train/mitotic-cells_label_map.pbtxt  \n",
      "   creating: valid/\n",
      " extracting: valid/mitotic-cells.tfrecord  \n",
      " extracting: valid/mitotic-cells_label_map.pbtxt  \n"
     ]
    }
   ],
   "source": [
    "#Downloading data from Roboflow\n",
    "#UPDATE THIS LINK - get our data from Roboflow\n",
    "%cd /content\n",
    "!curl -L \"https://app.roboflow.com/ds/ov346wjjfH?key=X9e3bSz1F5\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUd2wtfrqedy",
    "outputId": "169662dd-a467-4feb-ca33-a4975c0581a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
    "#test_record_fname = '/content/valid/mitotic-cells.tfrecord'\n",
    "#train_record_fname = '/content/train/mitotic-cells.tfrecord'\n",
    "train_record_fname = '/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_train'\n",
    "test_record_fname = \"/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_test\"\n",
    "label_map_pbtxt_fname = '/content/train/mitotic-cells_label_map.pbtxt'\n",
    "print(os.path.exists(train_record_fname))\n",
    "print(os.path.exists(test_record_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2MAcgJ53STW"
   },
   "source": [
    "# Configure Custom TensorFlow2 Object Detection Training Configuration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> In this section you can specify any model in the [TF2 OD model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and set up your training configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gN0EUEa3e5Un"
   },
   "outputs": [],
   "source": [
    "##change chosen model to deploy different models available in the TF2 object detection zoo\n",
    "MODELS_CONFIG = {\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    'efficientdet-d1': {\n",
    "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    'efficientdet-d2': {\n",
    "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "        'efficientdet-d3': {\n",
    "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 16\n",
    "    }\n",
    "}\n",
    "\n",
    "#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n",
    "#if you want to scale up tot larger efficientdet models you will likely need more compute!\n",
    "chosen_model = 'efficientdet-d2'\n",
    "\n",
    "num_steps = 10000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
    "num_eval_steps = 250 #Perform evaluation after so many steps\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kG4TmJUVrYQ7",
    "outputId": "1077c528-53ac-4787-d4bf-b4a5e515b36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/deploy\n",
      "--2021-06-08 19:34:34--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.128.128, 2607:f8b0:4001:c32::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.128.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 62929273 (60M) [application/x-tar]\n",
      "Saving to: efficientdet_d2_coco17_tpu-32.tar.gz\n",
      "\n",
      "efficientdet_d2_coc 100%[===================>]  60.01M   163MB/s    in 0.4s    \n",
      "\n",
      "2021-06-08 19:34:35 (163 MB/s) - efficientdet_d2_coco17_tpu-32.tar.gz saved [62929273/62929273]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download pretrained weights\n",
    "%mkdir /content/models/research/deploy/\n",
    "%cd /content/models/research/deploy/\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-nqYZtdtsgG",
    "outputId": "253a0219-d236-420e-c0e9-e5f78a796aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/deploy\n",
      "--2021-06-08 19:34:36--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4632 (4.5K) [text/plain]\n",
      "Saving to: ssd_efficientdet_d2_768x768_coco17_tpu-8.config\n",
      "\n",
      "ssd_efficientdet_d2 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-06-08 19:34:36 (44.0 MB/s) - ssd_efficientdet_d2_768x768_coco17_tpu-8.config saved [4632/4632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download base training configuration file\n",
    "%cd /content/models/research/deploy\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_ki9jOqxn7V",
    "outputId": "263f8849-2655-440e-92fd-97d6774c856c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#prepare\n",
    "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
    "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eA5ht3_yukT",
    "outputId": "7b3c5d4f-b5c2-4206-f9d2-c72514362f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/deploy\n",
      "writing custom configuration file\n"
     ]
    }
   ],
   "source": [
    "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "\n",
    "import re\n",
    "\n",
    "%cd /content/models/research/deploy\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    \n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "        \n",
    "    f.write(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEsOLOMHzBqF"
   },
   "outputs": [],
   "source": [
    "%cat /content/models/research/deploy/pipeline_file.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GMlaN3rs3zLe"
   },
   "outputs": [],
   "source": [
    "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxPj_QV43qD5"
   },
   "source": [
    "# Train Custom TF2 Object Detector\n",
    "\n",
    "* pipeline_file: defined above in writing custom training configuration\n",
    "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
    "* num_train_steps: how long to train for\n",
    "* num_eval_steps: perform eval on validation set after this many steps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQTfZChVzzpZ",
    "outputId": "3df5671a-f5a7-4166-a5ff-a78e2b9a32da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 19:35:44.652479: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-08 19:35:47.174543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-08 19:35:47.194811: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-06-08 19:35:47.194873: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6912c59256ec): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W0608 19:35:47.196067 140719193880448 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0608 19:35:47.196338 140719193880448 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0608 19:35:47.198761 140719193880448 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
      "I0608 19:35:47.206644 140719193880448 config_util.py:552] Maybe overwriting train_steps: 10000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0608 19:35:47.206833 140719193880448 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I0608 19:35:47.220381 140719193880448 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0608 19:35:47.220602 140719193880448 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0608 19:35:47.220666 140719193880448 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0608 19:35:47.225330 140719193880448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:35:47.257908 140719193880448 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0608 19:35:47.258239 140719193880448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:35:47.445437 140719193880448 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0608 19:35:47.445653 140719193880448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:35:47.833550 140719193880448 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0608 19:35:47.833755 140719193880448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:35:48.338015 140719193880448 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0608 19:35:48.338247 140719193880448 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0608 19:35:48.881687 140719193880448 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0608 19:35:48.881931 140719193880448 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0608 19:35:49.400380 140719193880448 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0608 19:35:49.400623 140719193880448 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0608 19:35:50.161614 140719193880448 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0608 19:35:50.161855 140719193880448 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0608 19:35:50.516577 140719193880448 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0608 19:35:50.603250 140719193880448 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0608 19:35:50.668877 140719193880448 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_train']\n",
      "I0608 19:35:50.689482 140719193880448 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_train']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_train']\n",
      "I0608 19:35:50.690525 140719193880448 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/pAItologos/processed_data/dataset/tfrecord/tfrecord_train']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0608 19:35:50.690790 140719193880448 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0608 19:35:50.690918 140719193880448 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0608 19:35:50.714221 140719193880448 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0608 19:35:50.753813 140719193880448 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0608 19:35:59.340744 140719193880448 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0608 19:36:04.611784 140719193880448 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-06-08 19:36:07.386379: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-08 19:36:07.393945: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-06-08 19:37:02.711161: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 905969664 exceeds 10% of free system memory.\n",
      "2021-06-08 19:37:03.446796: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 905969664 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KNv1N_hUibE"
   },
   "outputs": [],
   "source": [
    "#run model evaluation to obtain performance metrics\n",
    "#!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    #--pipeline_config_path={pipeline_file} \\\n",
    "    #--model_dir={model_dir} \\\n",
    "    #--checkpoint_dir={model_dir} \\\n",
    "#Not yet implemented for EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI9iCCxoNlAL"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Vk2146Ogil3"
   },
   "source": [
    "## Exporting a Trained Inference Graph\n",
    "Still to come for TF2 models, we will be updating this Colab notebook accordingly as the functionality is added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqaZ4v-vIuDl"
   },
   "outputs": [],
   "source": [
    "#see where our model saved weights\n",
    "%ls '/content/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnSEZIzl4M10"
   },
   "outputs": [],
   "source": [
    "#run conversion script\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = '/content/fine_tuned_model'\n",
    "\n",
    "#place the model weights you would like to export here\n",
    "last_model_path = '/content/training/'\n",
    "print(last_model_path)\n",
    "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsE_uVjlsz3u"
   },
   "outputs": [],
   "source": [
    "%ls '/content/fine_tuned_model/saved_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Vz2vJeCCyZR"
   },
   "source": [
    "# Run Inference on Test Images with Custom TensorFlow2 Object Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcR4PWC3KBau"
   },
   "outputs": [],
   "source": [
    "#downloading test images from Roboflow\n",
    "#export dataset above with format COCO JSON\n",
    "#or import your test images via other means. \n",
    "#%mkdir /content/test/\n",
    "#%cd /content/test/\n",
    "#!curl -L \"[YOUR LINK HERE]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxtm1NutE5vK"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qs1HJnEhyevJ"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f6DTolSDfXs"
   },
   "outputs": [],
   "source": [
    "%ls '/content/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFY75DfTDHaU"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "filenames = list(pathlib.Path('/content/training/').glob('*.index'))\n",
    "\n",
    "filenames.sort()\n",
    "print(filenames)\n",
    "\n",
    "#recover our saved model\n",
    "pipeline_config = pipeline_file\n",
    "#generally you want to put the last ckpt from training in here\n",
    "model_dir = str(filenames[-1]).replace('.index','')\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(\n",
    "      model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(\n",
    "      model=detection_model)\n",
    "ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "\n",
    "\n",
    "def get_model_detection_function(model):\n",
    "  \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "  @tf.function\n",
    "  def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = model.preprocess(image)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "  return detect_fn\n",
    "\n",
    "detect_fn = get_model_detection_function(detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ycfl7rnDT1D"
   },
   "outputs": [],
   "source": [
    "#map labels for inference decoding\n",
    "label_map_path = configs['eval_input_config'].label_map_path\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN1BzORoIzV4"
   },
   "outputs": [],
   "source": [
    "#run detector on test image\n",
    "#it takes a little longer on the first run and then runs at normal speed. \n",
    "import random\n",
    "\n",
    "#TEST_IMAGE_PATHS = glob.glob('/content/test/test/*.jpg')\n",
    "TEST_IMAGE_PATHS = glob.glob('/content/drive/MyDrive/pAItologos/processed_data/dataset/images/*.jpg')\n",
    "image_path = random.choice(TEST_IMAGE_PATHS)\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# Things to try:\n",
    "# Flip horizontally\n",
    "# image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "# Convert image to grayscale\n",
    "# image_np = np.tile(\n",
    "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(\n",
    "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'][0].numpy(),\n",
    "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "      detections['detection_scores'][0].numpy(),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=.005,\n",
    "      agnostic_mode=False,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,16))\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQ-N94cKB82o"
   },
   "source": [
    "## Congrats!\n",
    "\n",
    "Hope you enjoyed this!\n",
    "\n",
    "--Team [Roboflow](https://roboflow.ai)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Roboflow-TensorFlow2-Object-Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
